{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T04:35:03.383247Z"
    },
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from latex_formater import get_final_answer\n",
    "\n",
    "save_path = Path('~/GitHub/gold-ai-olympiad/data/MATH/Predictions/').expanduser()\n",
    "\n",
    "# load the results and combine them back into a single dataframe\n",
    "results = pd.concat([\n",
    "    pd.read_json(save_path / f)\n",
    "    for f in save_path.iterdir()\n",
    "    if f.suffix == '.json'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93bfae7c1e67ff7",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "results.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d97c7ff62774c8",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "class Metric():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def process(self, results):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, results):\n",
    "        return self.process(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e39424b9a26659a",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "class BoxedMatch(Metric):\n",
    "    def process(self, results):\n",
    "        results['boxed_pred'] = results['prediction'].apply(get_final_answer)\n",
    "        results['boxed_true'] = results['boxed']\n",
    "        results['boxed_match'] = results['boxed_true'] == results['boxed_pred']\n",
    "\n",
    "        # very slow, probably don't use\n",
    "        # results['match'] = results.apply(lambda x: is_equiv(x['boxed_true'], x['boxed_pred']), axis=1)\n",
    "\n",
    "        # set first columns to be ['dataset', 'i', 'model', 'method', 'boxed_true', 'boxed_pred', 'match', ...]\n",
    "        # cols = ['dataset', 'i', 'model', 'method', 'boxed_true', 'boxed_pred', 'boxed_match']\n",
    "        # cols.extend([col for col in results.columns if col not in cols])\n",
    "        return results  #[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20c117642d9d73",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from roscoe.score import (\n",
    "    SEQ_EMB_MODEL_TYPES,\n",
    "    Chain,\n",
    "    Evaluator,\n",
    "    REASONING_SCORES,\n",
    "    UNSUPERVISED_SCORES,\n",
    "    SENT_TRANS,\n",
    "    SIMSCE\n",
    ")\n",
    "from roscoe.utils import (\n",
    "    print_and_reset_max_gpu_memory,\n",
    "    save_scores,\n",
    "    split_gsm8k_gpt3_generations_to_steps,\n",
    ")\n",
    "\n",
    "\n",
    "class ReasoningSteps(Chain):\n",
    "    def __init__(self, line: str, type=\"regular\") -> None:\n",
    "        self.chain = self.parse_chain(line, type=type)\n",
    "\n",
    "    def parse_chain(self, chain: str, type: str) -> list[str]:\n",
    "        \"\"\"\n",
    "        Change formatting.\n",
    "\n",
    "        Returns list of steps in reasoning chain.\n",
    "        \"\"\"\n",
    "        if type == \"gsm8k_ref\":\n",
    "            return chain.split(\"IGNORE THIS. Ground truth here for reference. \")[\n",
    "                1\n",
    "            ].split('\\n')\n",
    "        elif type == \"gsm8k_hypo\":\n",
    "            return split_gsm8k_gpt3_generations_to_steps(reasoning=chain)\n",
    "        elif type == \"regular\":\n",
    "            return sent_tokenize(chain)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"{type} chain type is not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5842796c514e522",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# # get memory usage of evaluator.ppl_model\n",
    "# param_size = 0\n",
    "# for param in evaluator.grmr_model.parameters():\n",
    "#     param_size += param.nelement() * param.element_size()\n",
    "# buffer_size = 0\n",
    "# for buffer in evaluator.grmr_model.buffers():\n",
    "#     buffer_size += buffer.nelement() * buffer.element_size()\n",
    "# \n",
    "# size_all_mb = (param_size + buffer_size) / 1024 ** 3\n",
    "# print('model size: {:.3f}GB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d430593f7cf60",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from roscoe.score import Evaluator\n",
    "\n",
    "\n",
    "class ROSCOE(Metric):\n",
    "    def __init__(self, score_types=REASONING_SCORES, model_type=SIMSCE,\n",
    "                 transformer_model=\"facebook/roscoe-512-roberta-base\", ppl_model=\"gpt2-large\", discourse_batch=64,\n",
    "                 coherence_batch=16):\n",
    "        super().__init__()\n",
    "        self.evaluator = Evaluator(\n",
    "            score_types=score_types,\n",
    "            model_type=model_type,\n",
    "            transformer_model=transformer_model,\n",
    "            ppl_model=ppl_model,\n",
    "            discourse_batch=discourse_batch,\n",
    "            coherence_batch=coherence_batch,\n",
    "            hypos=[],\n",
    "            context=[],\n",
    "        )\n",
    "\n",
    "    def process(self, results):\n",
    "        hypos = [\n",
    "            ReasoningSteps(pred)\n",
    "            for pred in results['prediction']\n",
    "        ]\n",
    "        refs = [\n",
    "            ReasoningSteps(solution)\n",
    "            for solution in results['solution']\n",
    "        ]\n",
    "        context = [\n",
    "            ReasoningSteps(problem)\n",
    "            for problem in results['problem']\n",
    "        ]\n",
    "\n",
    "        self.evaluator.set_hypos(hypos)\n",
    "        self.evaluator.set_references(refs)\n",
    "        self.evaluator.set_context(context)\n",
    "        scores = self.evaluator.evaluate()\n",
    "        results['ROSCOE'] = scores\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d60dde0a2cf847",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# \n",
    "# torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "from comet import download_model, load_from_checkpoint\n",
    "\n",
    "\n",
    "class COMET(Metric):\n",
    "    def __init__(self, model_name=\"Unbabel/XCOMET-XL\", batch_size=16, gpus=1):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model_path = download_model(model_name)\n",
    "        self.model = load_from_checkpoint(self.model_path)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.gpus = gpus\n",
    "\n",
    "    def process(self, results):\n",
    "        data = [\n",
    "            {\n",
    "                \"src\": row['problem'],\n",
    "                \"mt\": row['prediction'],\n",
    "                \"ref\": row['solution']\n",
    "            } for _, row in results.iterrows()\n",
    "        ]\n",
    "        model_output = self.model.predict(data, batch_size=self.batch_size, gpus=self.gpus)\n",
    "        results[self.model_name] = model_output\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d90339dd3b567e5",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "boxed_match = BoxedMatch()\n",
    "results = boxed_match(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebef82b2e11ee483",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "boxed_accuracy = results.groupby(['model', 'dataset'])['boxed_match'].mean()\n",
    "model_accuracy = boxed_accuracy.groupby('model').mean()\n",
    "dataset_accuracy = boxed_accuracy.groupby('dataset').mean()\n",
    "\n",
    "plt.bar(model_accuracy.index, model_accuracy, edgecolor='black', linewidth=1, color='none')\n",
    "\n",
    "# plot each dataset as a separate point with model on the x axis and boxed_match on the y axis\n",
    "boxed_accuracy = results.groupby(['model', 'dataset'])['boxed_match'].mean()\n",
    "\n",
    "colors = pd.Categorical(boxed_accuracy.index.get_level_values('dataset'))\n",
    "scatter = plt.scatter(boxed_accuracy.index.get_level_values('model'), boxed_accuracy, c=colors.codes, cmap='tab10')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Boxed Match Accuracy')\n",
    "plt.title('Boxed Accuracy')\n",
    "handles, labels = scatter.legend_elements(prop='colors', alpha=0.6, fmt='{x:.0f}')\n",
    "labels = [colors.categories[int(label)].replace('_train', '') for label in labels]\n",
    "\n",
    "# sort the legend by the average accuracy\n",
    "sorted_idxs = dataset_accuracy.sort_values(ascending=False).index\n",
    "handles = [handles[colors.categories.get_loc(dataset)] for dataset in sorted_idxs]\n",
    "labels = [labels[colors.categories.get_loc(dataset)] for dataset in sorted_idxs]\n",
    "\n",
    "# add bars to the legend\n",
    "handles.append(plt.Rectangle((0, 0), 1, 1, fc='none', edgecolor='black'))\n",
    "labels.append('Average')\n",
    "\n",
    "plt.legend(\n",
    "    handles, labels,\n",
    "    title='Dataset',\n",
    "    loc='center left',\n",
    "    bbox_to_anchor=(1, 0.5)\n",
    ")\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938db185f647900f",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "roscoe = ROSCOE()\n",
    "results = roscoe(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
